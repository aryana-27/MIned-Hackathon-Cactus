{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQuBtty_z_2I",
        "outputId": "a70402a4-3c15-4b8a-b5a4-3cc2dc71203e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-docx, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.2 python-docx-1.1.2 python-pptx-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx python-pptx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2 gtts pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC9A86tU1yiU",
        "outputId": "e949b08a-84fb-42ae-c604-a355c6f0fe24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2024.12.14)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, PyPDF2, gtts\n",
            "Successfully installed PyPDF2-3.0.1 gtts-2.5.4 pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "# Create a new Document\n",
        "word_doc = Document()\n",
        "\n",
        "# Add a title and some paragraphs\n",
        "word_doc.add_heading('My First Document', level=1)\n",
        "word_doc.add_paragraph('This is a sample paragraph in the Word document.')\n",
        "word_doc.add_paragraph('Python-docx makes it easy to create and manipulate Word documents.')\n",
        "\n",
        "# Save the document\n",
        "word_doc.save(\"output.docx\")\n",
        "\n",
        "print(\"Word document created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwaqO3zx0NT4",
        "outputId": "d04edf1e-b47d-4fe3-bf11-5caabe22aed9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word document created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from pptx import Presentation\n",
        "\n",
        "def extract_text_without_references(pdf_path):\n",
        "    \"\"\"Extracts text from a PDF file, omitting references.\"\"\"\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        number_of_pages = len(reader.pages)\n",
        "        print(f\"Total Pages: {number_of_pages}\\n\")\n",
        "\n",
        "        extracted_text = \"\"\n",
        "        stop_keywords = [\"References\", \"Bibliography\", \"Citations\"]  # Keywords indicating references section\n",
        "        found_references = False\n",
        "\n",
        "        for i in range(number_of_pages):\n",
        "            page = reader.pages[i]\n",
        "            page_text = page.extract_text()\n",
        "\n",
        "            if page_text:\n",
        "                # Check if the page contains the start of references\n",
        "                for keyword in stop_keywords:\n",
        "                    if keyword.lower() in page_text.lower():  # Case-insensitive match\n",
        "                        found_references = True\n",
        "                        break  # Stop adding text after finding references\n",
        "\n",
        "                if not found_references:\n",
        "                    extracted_text += page_text + \"\\n\\n\"\n",
        "\n",
        "        # Display extracted text\n",
        "        print(\"\\nExtracted Text (Without References):\\n\")\n",
        "        print(extracted_text)\n",
        "\n",
        "        # Save extracted text to a file\n",
        "        with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(extracted_text)\n",
        "\n",
        "        print(\"\\nText successfully extracted and saved in 'extracted_text.txt'.\")\n",
        "\n",
        "        return extracted_text  # Return the extracted text for further processing\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: The file was not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "def create_ppt_from_text(text):\n",
        "    \"\"\"Creates a PowerPoint presentation from extracted text.\"\"\"\n",
        "    ppt = Presentation()\n",
        "\n",
        "    # Split the text into sections based on double newlines\n",
        "    slides = text.strip().split('\\n\\n')  # Adjust delimiter if needed\n",
        "\n",
        "    for slide_text in slides:\n",
        "        slide_layout = ppt.slide_layouts[1]  # Using layout with title and content\n",
        "        slide = ppt.slides.add_slide(slide_layout)\n",
        "\n",
        "        title = slide.shapes.title\n",
        "        content = slide.placeholders[1]\n",
        "\n",
        "        # Split slide_text into lines, assuming the first line is the title\n",
        "        lines = slide_text.split('\\n')\n",
        "        title.text = lines[0]  # First line as title\n",
        "        content.text = '\\n'.join(lines[1:])  # Remaining lines as content\n",
        "\n",
        "    ppt.save(\"output.pptx\")\n",
        "    print(\"PowerPoint presentation created successfully!\")\n",
        "\n",
        "# Specify the PDF file path\n",
        "pdf_path = \"intelligent.pdf\"  # Change to full path if needed\n",
        "\n",
        "# Extract text from PDF\n",
        "extracted_text = extract_text_without_references(pdf_path)\n",
        "\n",
        "# Create PowerPoint from extracted text if any text was extracted\n",
        "if extracted_text:\n",
        "    create_ppt_from_text(extracted_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hePbUCND1QKQ",
        "outputId": "7cfbfdcf-506b-43c0-d34f-45b52eaf6046"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Pages: 5\n",
            "\n",
            "\n",
            "Extracted Text (Without References):\n",
            "\n",
            "4thMediterranean Conference on Embedded ComputingMECO - 2015Budva, Montenegro  \n",
            " \n",
            "An Intelligent System  for Diabetes Prediction  \n",
            " \n",
            "Zhilbert Tafa  \n",
            "Dep. of  Computer Science  \n",
            "University for Business and Technology  \n",
            "Prishtina, Kosovo  \n",
            "tafaul@t -com.me  \n",
            " Nerxhivane Pervet ica \n",
            "Bertran Karahoda  \n",
            "Dep. of Computer Science  \n",
            "University for Business and Technology  \n",
            "Prishtina, Kosovo  \n",
            "np32972@ubt -uni.net  \n",
            "b.karahoda@ubt -uni.net\n",
            " \n",
            " \n",
            "Abstractâ€”With the emerging increase of diabetes, that recently \n",
            "affects around 346 million people, of which more than one-third \n",
            "go undetected in early stage, a strong need for supporting the \n",
            "medical deci sion-making process  is generated . A number of  \n",
            "researches have focused either in using one of the algorithms or \n",
            "in the comparisons of the performances of algorithms on a given, \n",
            "usual ly predefined and static datasets that are accessible through \n",
            "the Internet.  This paper focuses on the joint implementation of \n",
            "the support vector machine (SVM) and N aÃ¯ve Bayes statistical \n",
            "modeling , in the dataset acquired from the medical examinations \n",
            "of 40 2 patients , in order to improve the computer -supported \n",
            "diagnosis reliability . The dataset contains some attributes that \n",
            "have not been previously used in computer -based evaluations . \n",
            "The results show that the joint implementation of two algorithms \n",
            "improves s ignificantly the overall reliability  of the system \n",
            "outcome , which is crucial in the computer -supported diabetes \n",
            "diagnostic process .   \n",
            "Keywords - algorithms;  diabetes ; joint implementation,  machine \n",
            "learning ; NaÃ¯ve Bayes ; support vector machine . \n",
            "I.  INTRODUCTION  \n",
            "Diabetes is a chronic disease caused by the increase in \n",
            "blood sugar , mainly either due to the less production or no \n",
            "production of insulin in body ( type 1 diabetes ), or due to  the \n",
            "fact that cells do not respond to the produced insulin  (type 2 \n",
            "diabetes) . In recent years, the number of diabetic patients has  \n",
            "increased drastically , as noted in [1],  mainly due to the aging \n",
            "population and  irregular western food habits . According to the \n",
            "World Health Organization , diabetes affects around 346 \n",
            "million people in the wo rld, with the prevalence of diabetes \n",
            "type 2. Moreover, diabetes is the major cause for heart stroke, \n",
            "kidney failure, lower -limb amputations and blindness. As \n",
            "presented in [2 ], the absence of symptoms, or the absence of \n",
            "recognition of the indicators in the patientâ€™s data , may lead to \n",
            "the pre -diabetes or diabetes condition that go es undetected \n",
            "even in more than one-third of people that ar e later diagnosed \n",
            "with diabetes.  \n",
            "During the clinical examinations of various forms, lots of \n",
            "data are acquired from patients. The development of the \n",
            "computer -based methods that would enable the high \n",
            "probability recognition of pre -diabetic or diabetic condition can \n",
            "be an efficient support t o the decision making in healthcare.  Machine learning is  the area of artifici al intelligence  that \n",
            "uses the statistical analyse s, and is recognized to be a \n",
            "promising area that, based on the given dataset of diabetics,  can \n",
            "help in patient classification or probability prediction regarding \n",
            "the patientâ€™s pre-diabetic or diabetic condition.  The main \n",
            "strength of these methods is contained in the ability of the \n",
            "algorithms to learn from data and to use that knowledge for \n",
            "later predictions and decisions. There are a number of machine \n",
            "learning and statistical modeling approaches that so far have \n",
            "been involved in various aspects of solving the problem . \n",
            "According to [3 ], although other classifiers perform well, the \n",
            "SVM outperforms other  classifiers with respect to accuracy, \n",
            "sensitivity, specificity , and precision.  \n",
            "This paper presents a  joint Matlab implementation of the \n",
            "SVM and N aÃ¯ve Bayes methods in a new dataset acquired from \n",
            "the patients examined for diabetes in Kosovo. The developed \n",
            "diagnostic tool enables the in telligent computer -based \n",
            "prediction on diabetes , based on the previously acquired \n",
            "values. The statistical analysis shows the high accuracy of data \n",
            "classification.  Also, the proposed joint implementation of two \n",
            "algorithms aims to improve the  reliability of the decision by \n",
            "using the power of both algorithms in minimizing their \n",
            "individual weakness .   \n",
            "The rest of the paper is structured as follows. Related work \n",
            "on the topic is presented in Section II . In section III, the \n",
            "experimental  setup and the  implementation are  presented. \n",
            "Results are shown and discussed in Section IV  while the \n",
            "Section V concludes the work . \n",
            "II. RELATED WORK  \n",
            "A number of research efforts  have  been directed in \n",
            "involving the machine learning algorithms to the design of \n",
            "intelligent healthcare applications,  especially in disease \n",
            "detection.  Most of them have focused on heart disease, cancer \n",
            "detection, and diabetes.  An analytical study of several \n",
            "algorithms , focused on classification of d iabetes mellit us data , \n",
            "is presented in [1 ]. The algorithms have mostly  focused on \n",
            "detection of pre -diabetes, which was recognized in [4 ] as a \n",
            "relatively strong  indication for the future development of \n",
            "diabetes. A recent study in this direction is given in [5 ], where \n",
            "two machine learning techniques, namely SVM and ANN \n",
            "\n",
            "4thMediterranean Conference on Embedded ComputingMECO - 2015Budva, Montenegro  \n",
            " \n",
            "(Artificia l Neural Networks) , are used to predict pre -diabetes \n",
            "in Korean population.  A similar approach is used in studying \n",
            "the correlation for hematological parameters and glucose level \n",
            "for identification of diabetes  [6]. \n",
            "In general, the research focus is to conduc t some of the \n",
            "supervised learning  algorithms on the given dataset and \n",
            "extract the knowledge about the prediction of diabetes based \n",
            "on given values of the appropriate attributes. In [7], the SVM \n",
            "implementation gives the prediction accuracy of 94 %. Another  \n",
            "implementation of the SVM in detec ting the diabetes is given \n",
            "in [8 ]. Here, t he SVM classifier , however , performs only 78 % \n",
            "of accuracy . A method for prediction of diabetes by using  \n",
            "Bayesian network is given in [9 ] while the authors in [10] \n",
            "separately use NaÃ¯ve Bayes and k -nearest neighbor algorithm.  \n",
            "Most of the mentioned researches , rely on Pima Indian \n",
            "database of diabetic, and therefore have the same attributes  \n",
            "and similar conclusions. Furthermore, they treat one or two \n",
            "algorithms independently to compar e the efficiency of the \n",
            "algorithms between each other.  Some studies, however, \n",
            "recommend the hybrid use of a distance -based algorithm and a \n",
            "statistical based method [11] or the combination of \n",
            "classification and clustering [1].  \n",
            "In contrast to the most of the  mentioned materials and \n",
            "methodologies,  this paper treats original dataset , with different \n",
            "attributes,  extracted from the medical examinations in Kosovo.  \n",
            "Beside the algorithm performance evaluations, t he aim of the \n",
            "paper  is not only to analyze the dataset and to provide a \n",
            "supporting tool for diabetes detection, but also to improve the \n",
            "derived decision reliability  by jointly using two machine \n",
            "learning algorithms . This creates a more reliable zone (with \n",
            "the answers yes/no on diabetes) and a â€œgrey zoneâ€ that would \n",
            "direct the decision making process to the further clinical \n",
            "examinations.    \n",
            "III. MATERIALS AND IMPLEMENTATION METHODS  \n",
            "A. Dataset description  \n",
            "Dataset consists of 402 instances  taken from three different \n",
            "locations in Kosovo. During the data a cquisition process, the \n",
            "appropriate importance is given to the patientâ€™s data privacy \n",
            "and anonymity.  The attributes of the database are : BMI (body \n",
            "mass index), glucose level before meal and after meal, the \n",
            "systolic and diastolic blood pressure, the heredit arily factor, the \n",
            "regular diet, and daily physical activities. The last two \n",
            "attributes are evaluated as follows. Regarding the issue of \n",
            "regular diet,  while relying on inputs from the medical \n",
            "clinicians,  patients  were asked if they took  their meals in \n",
            "appro ximately same equidistant daily intervals at least three \n",
            "times a day and also if their meals were  not voluminous. With \n",
            "these answers being positive , we consider  that a patient is \n",
            "having  the regular diet. On the other hand , according to the \n",
            "U.S. Center  for Disease Control and Prevention (CDCP), the \n",
            "adult person  is considered to be physically active if he/she \n",
            "conducts the 150 -200 min of physical activities a week.  With \n",
            "the answers on the family history questions, and i n accordance \n",
            "to the above given threshold s, the answers of the examinee regarding the  last three questions are mapped into two values: 1 \n",
            "and 0.  \n",
            "The range s of the values  of all attributes  are given in Table I.  \n",
            "TABLE I.  THE RANGES OF THE ATTRIBUTES  \n",
            "Attribute  Value range  \n",
            "From  To \n",
            "BMI  15 40 \n",
            "Pre meal glucose  3.5 19 \n",
            "Post meal glucose  4.9 22.8 \n",
            "Diastolic blood pressure  55 110 \n",
            "Systolic blood pressure  90 200 \n",
            "Family history of diabetes  No (0)  Yes (1)  \n",
            "Regular diet  No (0)  Yes (1)  \n",
            "Physical activities  No (0)  Yes (1)  \n",
            " \n",
            "After acquiring the given initial data from patients, and \n",
            "after the extensive laboratory examinations and continuous \n",
            "monitoring, 80 of patie nts were diagnosed with type 2 \n",
            "Diabetes. The presence of diabetes i n an instance was labeled \n",
            "with B oolean 1. The rest of patients were not diagnosed with \n",
            "diabetes , which results in  number of 322 Boolean zeros in the \n",
            "dataset .   \n",
            "B.  The SVM implementation  \n",
            "The SVM algorithm represents the instances as points in \n",
            "space, mapped so that separate classes are divided by a clear \n",
            "gap. The aim is to find the maximum -margin hyper plane â€“ the \n",
            "one that gives the greatest separation between the classes. The \n",
            "instances that are closest to the maximum -margin hyper plane \n",
            "are called support vectors. Support vectors are chosen based on \n",
            "the po rtion of the dataset that represents the training set.  \n",
            "Support vectors of two classes enable the creation of two \n",
            "parallel hyper planes. The larger the margin between these two \n",
            "hyper planes, the better the generalization error of the \n",
            "classifier.  \n",
            "Training d ata points can be represented in form:  \n",
            "{(X1, Y1), (X2, Y2)â€¦., (Xn, Yn)}  \n",
            " \n",
            "where Xi is a k -dimensional vector and Yi is +1 or -1 \n",
            "denoting the class to which a given point belongs to.  \n",
            "The training data is then divided by a hyper plane of general \n",
            "form:  \n",
            "ğ‘Šâˆ—ğ‘‹+ğµ=0              (1) \n",
            "Where W is k -dimensional vector, perpendicular to the hyper \n",
            "plain and B is scalar. Two parallel hyper planes that belong to \n",
            "two different classes can be described by equations:  \n",
            "\n",
            "4thMediterranean Conference on Embedded ComputingMECO - 2015Budva, Montenegro  \n",
            " \n",
            "ğ‘Šâˆ—ğ‘‹+ğµ=1           (2) \n",
            "ğ‘Šâˆ—ğ‘‹+ğµ=âˆ’1           (3) \n",
            "The distance between the hyper planes is 2/|W| so the aim \n",
            "is to minimize |W|. The semantics behind the \n",
            "multid imensional formulations  (1)-(3) is given in [12 ] and \n",
            "further process of minimization of factor 2/|W| is explained in \n",
            "[13].  \n",
            "C. The N aÃ¯ve Bayes implementation  \n",
            "The N aÃ¯ve Bayes classification is based on the probabilistic \n",
            "Bayes theory. As noted in [11 ], the N aÃ¯ve Bayes statistical \n",
            "algorithm is a frequently used method in prediction problem. \n",
            "The implementation of the statistical modeling is based on \n",
            "linear function. T heoretically , it usually  means the appliance \n",
            "of unrealistic assumption that the attributes are equally \n",
            "important and independent. Th e real life dataset consists  of \n",
            "attributes that are certainly not equally important or \n",
            "indep endent, but, a s noted in [12 ] and also shown in this \n",
            "paper, it leads to a simple scheme that, again, works \n",
            "surpri singly well in practice.   \n",
            "While keeping in mind the above mentioned independency \n",
            "assumption, the calculation of the probability tha t a given \n",
            "record belongs t o class Y=C, can be calculated as the product \n",
            "of probability that each of value s of the i recordâ€™s attributes  \n",
            "belong to class C, i.e.,  \n",
            " \n",
            "ğ‘ƒ ğ‘‹ ğ‘Œ=ğ¶ =  ğ‘ƒ(ğ‘\n",
            "ğ‘–=1ğ‘‹ğ‘– ğ‘Œ=ğ¶                                      (4) \n",
            "The probability that a given value of the attribute belongs \n",
            "to class ğ‘¦ğ‘—, when the dataset contains numerical inputs, can \n",
            "often generally be calculated by using the Gaussian \n",
            "distribution function, i.e.,  \n",
            "ğ‘ƒ ğ‘‹ğ‘–=ğ‘¥ğ‘– ğ‘Œ=ğ‘¦ğ‘— =1\n",
            " 2ğœ‹ğœğ‘–ğ‘—ğ‘’âˆ’ ğ‘¥ğ‘–âˆ’ğœ‡ğ‘–ğ‘— 2\n",
            "2ğœğ‘–ğ‘—2                               (5) \n",
            " \n",
            "Finally, the probability that a given record will be classified in \n",
            "class C, can be formulated with:  \n",
            " \n",
            "ğ‘ƒ ğ¶ ğ‘¥1,â€¦ğ‘¥ğ‘› =ğ‘ƒ ğ¶ ğ‘ƒ ğ‘¥1,â€¦,ğ‘¥ğ‘› ğ¶ \n",
            "ğ‘ƒ ğ‘¥1,â€¦ğ‘¥ğ‘›                                            (6) \n",
            "D. The proposed architecture  \n",
            "The system consists of the following elements. Two \n",
            "machines, namely SVM and NaÃ¯ve Bayes classifier , build their \n",
            "classifiers based on the training sets. Afterward, they are ready \n",
            "to perform the classification of a given record. The output can \n",
            "belong to one of two classes: class 0 (no diabetes) and class 1 \n",
            "(diabetes). If the outcomes from both classifiers are equal, the \n",
            "record is classified as belonging to class 0 or class 1. If the \n",
            "output is different, then the record is considered as still \n",
            "unclassified (gre y zone).  \n",
            "The SVM algorithm is  implement ed by using \n",
            "bioinformatics tool  in Matlab  while NaÃ¯ve Bayes implementation is constructed manually, also in Matlab . \n",
            "Matlab was  chosen due to its flexibility and ability to work \n",
            "with various file formats. By using the  Matlab function, the \n",
            "data are divided into  the training set and the testing set . The \n",
            "classifier is extracted from the training set while the instances \n",
            "from the testing set are tested on the derived classifier. The \n",
            "SVM algorithm uses the polynomial kernel.  In order to \n",
            "mitigate any bias caused by samples chosen for holdout, the \n",
            "repeated holdout method  of error estimation is used. In this \n",
            "direction, the process of classifier performance evaluation is \n",
            "repeated 100 times with the classifier performance evaluate d \n",
            "in each of the iteration.  \n",
            "IV. RESULTS  AND DISCUSSIONS  \n",
            "Prior to building the application, analyzing data, and \n",
            "evaluating the classification performance, sample size is \n",
            "conducted to analysis in accordance to the methodology \n",
            "described in [14]. With the given nu mber of population, the \n",
            "given response distribution of  diabetes in Kosovo, and  the \n",
            "given confidence level of 98%, the margin of error that occurs \n",
            "due to the limited number of examinee is expected to be in the \n",
            "range of 1,62 %.  \n",
            "The developed  Matlab -based application works in two \n",
            "modes: the assessment mode and the data acquisition mode. \n",
            "The GUI is given in Fig. 1 . \n",
            " \n",
            "Fig. 1: Diabetes diagnostic a pplication GUI  \n",
            "The data acquisition  mode enables for the addition of new \n",
            "records, in order to increas e the sample size and the \n",
            "classification accuracy. The  assessment mode gives the \n",
            "prediction of pre -diabetic or diabetic condition on each of the \n",
            "newly added record.  \n",
            "The prediction on new record is based on the execution of \n",
            "both SVM and NaÃ¯ve Bayes classifi cation  on previous \n",
            "instances with different randomly chosen training sets . If both \n",
            "classifiers classify the record as being positive or negative, then \n",
            "we consider the given output of the classifier for a specific \n",
            "record as having high reliability . Otherwis e, if the outputs  are \n",
            "different , the patient needs to be further monitored on diabetes.   \n",
            "For the simplicity reasons, by incorporating the \n",
            "stratification, the data are quasi -randomly split into  two equal \n",
            "sets - 201 instances for training and 201 instances f or \n",
            "evaluating the performances . In general, these two sets are only \n",
            "approximately equal, since  the number s of instances  for \n",
            "\n",
            "\n",
            "4thMediterranean Conference on Embedded ComputingMECO - 2015Budva, Montenegro  \n",
            " \n",
            "training and testing are  selected automatically by crossvalind  \n",
            "Matlab function. In order to find the average value of the \n",
            "classifier sâ€™ accuracy , the process of random selection of the \n",
            "training set and test set  along with the classifier performance \n",
            "evaluation on each random selection is repeated 100  times .  \n",
            "The results show the mean value of the SVM classifier \n",
            "performance  - accuracy  of 95, 52 % while for the NaÃ¯ve Bayes \n",
            "classifier  the classifier accuracy is 94,  52%. Both values vary \n",
            "in +/- 1% of classification performance margin during various \n",
            "iterations.  This also shows for the high stability of classifier.  \n",
            "The average number  of correctly and incorrectly classified \n",
            "records is calculated  for both classifiers and the results are \n",
            "given in Table II  along with the structure of the sample \n",
            "distribution for training and testing the system . \n",
            "TABLE II.  CLASSIFICATION AND THE AVERAGE ACCURACY  \n",
            " No. of \n",
            "record s Train set \n",
            "/ test set  No. of \n",
            "correctly \n",
            "classified  No. of \n",
            "incorrectly \n",
            "classified \n",
            "records  Classifier \n",
            "performance \n",
            "(mean value)  \n",
            "SVM  402 201/201  192 9 95.52%  \n",
            "NaÃ¯ve \n",
            "Bayes  402 201/201  190 11 94.53 % \n",
            " \n",
            "As can be noted, and as expected, in terms of the overall \n",
            "average classification accuracy, SVM over performs the NaÃ¯ve \n",
            "Bayes classification, but the difference in classifier \n",
            "performance is surprisingly small.  \n",
            "The performances are also estimated in terms of other \n",
            "multi -class classification  measures such as precision and \n",
            "recall. For a specific class, these two measures are calculated \n",
            "as follows:  \n",
            " \n",
            "ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›ğ‘‹=ğ‘‡ğ‘ƒğ‘‹\n",
            "ğ‘‡ğ‘ƒğ‘‹+ğ¹ğ‘ƒğ‘‹           (7) \n",
            " \n",
            "ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™ğ‘‹=ğ‘‡ğ‘ƒğ‘‹\n",
            "ğ‘‡ğ‘ƒğ‘‹+ğ¹ğ‘ğ‘‹                         (8) \n",
            " \n",
            "The notations TP, FP and FN refer to the number of data \n",
            "classified as true positive, false positive and false negative, \n",
            "i.e., the data correctly classified in class X, the data that \n",
            "belong to another class and are incorrectly classified in class \n",
            "X, and the  data that should have been classified in class X \n",
            "whereas are classified in another class..  \n",
            "The results regarding the precision and recall of classes \n",
            "YES and NO are given in Table III.  \n",
            "TABLE III.  PRECISION AND RECALL  \n",
            " Precision \n",
            "(Class NO)  Recall \n",
            "(ClassNO)  Precision \n",
            "(Class YES)  Recall  \n",
            "(Class YES)  \n",
            "SVM  0.97 0.975  0.892  0.868  \n",
            "NaÃ¯ve \n",
            "Bayes  0.981  0.951  0.814  0.921  \n",
            " \n",
            "The joint implementation aims to improve the reliability of \n",
            "the decision in case when both algorithms give the same outcome, when we consider the outcome to be valid. \n",
            "Otherwise, when the outcomes are different, we consider the \n",
            "decision to be unreliable and hence invalid.  \n",
            "After the repeated joint implementation of both algorithms, \n",
            "the average rate of the valid outcomes turns out to be 94, 77 % \n",
            "with the expected lower bound of approximately 90, 3 %. This \n",
            "means that the major number (94, 77%) of new patients that \n",
            "need to be classified regarding the likeness of diabetic \n",
            "condition, will be classified the same way by two inde pendent \n",
            "classifiers. The difference of 5.23 % in the results of \n",
            "classifiers exists due to their individual weaknesses and can \n",
            "also be related to the dataset. Among the valid  outcomes, the \n",
            "derived accuracy of the dec ision is now improved up to 97,6 \n",
            "%, which  significantly over performs both classifiers \n",
            "individually.   \n",
            "V. CONCLUSIONS AND FUTUR E WORK  \n",
            "The research efforts presented in this paper are focused in \n",
            "developing and the evaluation of a computer -based support tool \n",
            "for the diabetes  detection .  \n",
            "The presented approach is based on the joint \n",
            "implementation of two algorithms in Matlab that have been \n",
            "executed on the newly acquired dataset with the different \n",
            "attributes as compared to the previous work in this field . The \n",
            "algorithms are executed and eval uated independently but the \n",
            "decision making is based on the joint outcomes from both \n",
            "algorithms.  The aim of this approach is to make the decision \n",
            "more reliable.   \n",
            "As shown in the paper, both SVM and naÃ¯ve Bayes \n",
            "algorithm have individually shown high overall classifier \n",
            "performances  of 95 , 52% and 94, 52%, respectively.  The joint \n",
            "implementation on the same, newly added record leads to one \n",
            "of the three answers: a) the patient is diagnosed with diabetes \n",
            "(or pre -diabetic condition), b) the patient is not d iagnosed as \n",
            "having the mentioned condition, and c) the patient is further \n",
            "directed to the additional clinical examinations.  If two \n",
            "algorithms show different results, the answer is classified as \n",
            "condition c). Otherwise, the accuracy of the answers a) or  b) , \n",
            "as shown in the paper, is improve d up to the value of 97,6%.  \n",
            "The presented methodology minimizes the false negative \n",
            "answers, which is a crucial issue in medical diagnoses.  \n",
            "Finally, the construction approach, the architecture, and the \n",
            "evaluation of a diab etes classification tool presented in this \n",
            "paper, should provide an important guideline to further \n",
            "construction of the similar applications on improving and \n",
            "helping the decision making process in disease detection.  The \n",
            "development of a user -friendly and wi dely accessible \n",
            "application would enable the personal self -screening on \n",
            "diabetic or pre -diabetic condition which is crucial to the disease \n",
            "treatment performance.  \n",
            "The future work will focus on further quantitative \n",
            "evaluation s of the developed tool  regarding the extensive \n",
            "clinical examinations and results . Also, other methods should \n",
            "be involved in finding the best fit in the sense of accuracy, \n",
            "processing time, etc. The influence of cultural -related biases \n",
            "(such as those related to the nutrition struc ture and habits) \n",
            "\n",
            "\n",
            "\n",
            "Text successfully extracted and saved in 'extracted_text.txt'.\n",
            "PowerPoint presentation created successfully!\n"
          ]
        }
      ]
    }
  ]
}